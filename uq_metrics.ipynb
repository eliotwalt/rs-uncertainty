{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UQ metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio, yaml, os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import scipy\n",
    "from typing import *\n",
    "\n",
    "PREDICTIONS_DIR = Path(\"results/dev/2023-03-14_15-45-23\")\n",
    "PKL_DIR = Path('data/pkl/2021-05-18_10-57-45')\n",
    "GT_DIR = Path('data/preprocessed')\n",
    "\n",
    "EAST = ['346', '9', '341', '354', '415', '418', '416', '429', '439', '560', '472', '521', '498',\n",
    "        '522', '564', '764', '781', '825', '796', '805', '827', '891', '835', '920', '959', '1023', '998',\n",
    "        '527', '477', '542', '471']\n",
    "WEST = ['528', '537', '792', '988', '769']\n",
    "NORTH = ['819', '909', '896']\n",
    "ALL = EAST + WEST + NORTH\n",
    "\n",
    "with (PKL_DIR / 'stats.yaml').open() as fh:\n",
    "    # load training set statistics for data normalization\n",
    "    stats = yaml.safe_load(fh)\n",
    "    labels_mean = np.array(stats['labels_mean'])\n",
    "\n",
    "projects = [f.stem.split(\"_\")[0] for f in PREDICTIONS_DIR.glob('*_mean.tif') if f.stem.split(\"_\")[0] in ALL]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative metrics\n",
    "\n",
    "Let $\\mathcal{D}=\\left\\{(\\mathbf{x}_i, \\mathbf{y}_i) \\in \\mathcal{X}\\times\\mathcal{Y}\\right\\}_{i=1,\\ldots,N}$ be the test set and $\\mathcal{P}=\\left\\{(\\hat\\mu, \\hat\\sigma^2)  \\in \\mathcal{X}\\times\\mathcal{Y}\\right\\}_{i=1,\\ldots,N}$ be the corresponding pixel-wise predicted mean and variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_uce(variance, mean, gt, n_bins):\n",
    "    d = gt.shape[0]\n",
    "    # Mask nan\n",
    "    mask = (~np.isnan(variance) & ~np.isnan(mean)).all(0)\n",
    "    variance = variance[:,mask]\n",
    "    mean = mean[:,mask]\n",
    "    gt = gt[:,mask]\n",
    "    # Compute UCE for each variables\n",
    "    uce = np.empty((d,))\n",
    "    prop_in_bins = np.empty((d, n_bins))\n",
    "    uncertainty_in_bins = np.empty((d, n_bins))\n",
    "    variance_in_bins = np.empty((d, n_bins))\n",
    "    for i, (var, mu, tgt) in enumerate(zip(variance, mean, gt)):\n",
    "        # Linear binning\n",
    "        bins = np.linspace(var.min(), var.max(), n_bins)\n",
    "        # Get variance bin indexes\n",
    "        bins_ids = np.digitize(var, bins=bins)\n",
    "        # Loop on bins to compute statistics\n",
    "        _uce = 0\n",
    "        for bin_id in np.unique(bins_ids)-1:\n",
    "            # Select bin\n",
    "            pos = bins_ids==bin_id+1\n",
    "            prop_in_bin = pos.astype(\"float\").mean() # bin_size / N\n",
    "            bin_var = var[pos]\n",
    "            bin_mean = mu[pos]\n",
    "            bin_tgt = tgt[pos]\n",
    "            # Compute stats\n",
    "            mean_uncertainty = bin_var.mean()\n",
    "            mean_variance = ((bin_mean-bin_tgt)**2).mean()\n",
    "            _uce += prop_in_bin * np.abs(mean_variance - mean_uncertainty)\n",
    "            # keep result\n",
    "            prop_in_bins[i,bin_id] = prop_in_bin\n",
    "            uncertainty_in_bins[i,bin_id] = mean_uncertainty\n",
    "            variance_in_bins[i,bin_id] = mean_variance\n",
    "        uce[i] = _uce\n",
    "    return uce, uncertainty_in_bins, variance_in_bins, prop_in_bins\n",
    "\n",
    "def nan_ence(variance, mean, gt, n_bins):\n",
    "    _, bins_mean_mse, bins_mean_variance, bins_proportions = nan_uce(variance, mean, gt, n_bins)\n",
    "    bins_mean_rmse, bins_mean_std = np.sqrt(bins_mean_mse), np.sqrt(bins_mean_variance)\n",
    "    ence = (np.abs(bins_mean_std-bins_mean_rmse) / bins_mean_std).mean(1)\n",
    "    return ence, bins_mean_mse, bins_mean_variance, bins_proportions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Uncertainty Calibration Error (UCE) [Laves 2020, Laves 2021, Levi 2019, Becker 2023] and Expected Normalized Calibration Error (ENCE) [Levi 2019, Zhou 2021a]\n",
    "\n",
    "The code above is correct BUT it computes UCE/ENCE on a single sample which does not really make sense. We need to compute it on all the predictions/gt pairs. To do so, we could for instance, create a 1d vector for each variable that contains the values for all the predicted pixels. Then, we can use a similar code to compute the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = projects[0]\n",
    "mean_file = os.path.join(PREDICTIONS_DIR, f\"{project}_mean.tif\")\n",
    "with rasterio.open(mean_file) as fh:\n",
    "    mean = fh.read(fh.indexes)\n",
    "with rasterio.open(PREDICTIONS_DIR / (project + '_variance.tif')) as fh:\n",
    "    variance = fh.read(fh.indexes)\n",
    "with rasterio.open(GT_DIR / (project + '.tif')) as fh:\n",
    "    gt = fh.read(fh.indexes)\n",
    "    gt_mask = fh.read_masks(1).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.57581110e+00, 1.91647382e+00, 2.77684128e+03, 1.15106952e-03,\n",
       "        6.44200623e+03]),\n",
       " array([0.41494112, 0.55113869, 0.99615498, 0.63229099, 0.99686558]))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_uce(variance, mean, gt, 20)[0], nan_ence(variance, mean, gt, 20)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85b5837dbff4766d9191b34df77a27f59ea2878bea160d10262c984d96904546"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

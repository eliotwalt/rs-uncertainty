{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import rasterio\n",
    "import argparse\n",
    "import yaml\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from argparse import Namespace\n",
    "import matplotlib.pyplot as plt\n",
    "os.chdir(\"/scratch/ewalt/pdm/rs-uncertainty/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pjoin(*subs): return Path(os.path.abspath(os.path.join(*subs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "args = Namespace()\n",
    "args.cfg = Path(\"./config/evaluate_testset/baseline.yaml\")\n",
    "with args.cfg.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    cfg = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_bands': [1, 2, 3, 4, 5],\n",
       " 'variable_names': ['P95', 'MeanH', 'Dens', 'Gini', 'Cover'],\n",
       " 'projects_east': ['346',\n",
       "  '9',\n",
       "  '341',\n",
       "  '354',\n",
       "  '415',\n",
       "  '418',\n",
       "  '416',\n",
       "  '429',\n",
       "  '439',\n",
       "  '560',\n",
       "  '472',\n",
       "  '521',\n",
       "  '498',\n",
       "  '522',\n",
       "  '564',\n",
       "  '764',\n",
       "  '781',\n",
       "  '825',\n",
       "  '796',\n",
       "  '805',\n",
       "  '827',\n",
       "  '891',\n",
       "  '835',\n",
       "  '920',\n",
       "  '959',\n",
       "  '1023',\n",
       "  '998',\n",
       "  '527',\n",
       "  '477',\n",
       "  '542',\n",
       "  '471'],\n",
       " 'projects_west': ['528', '537', '792', '988', '769'],\n",
       " 'projects_north': ['819', '909', '896'],\n",
       " 'pkl_dir': 'data/2023-04-05_18-58-33',\n",
       " 'prediction_dir': 'results/2023-04-06_10-52-04_baseline',\n",
       " 'gt_dir': 'assets/data/preprocessed',\n",
       " 'num_bins': 1000}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = cfg[\"projects_east\"]+cfg[\"projects_west\"]+cfg[\"projects_north\"]\n",
    "# with Path(\"/scratch/ewalt/pdm/rs-uncertainty/assets/data/pkl/2021-05-18_10-57-45/stats.yaml\").open() as f:\n",
    "#     stats = yaml.safe_load(f)\n",
    "# labels_mean = np.array(stats[\"labels_mean\"]).reshape(5,1,1)\n",
    "# labels_std = np.array(stats[\"labels_std\"]).reshape(5,1,1)\n",
    "with pjoin(cfg[\"pkl_dir\"], \"stats.yaml\").open(\"r\", encoding=\"utf-8\") as f:\n",
    "    stats = yaml.safe_load(f)\n",
    "labels_mean = np.array(stats[\"labels_stats\"][\"mean\"]).reshape(5,1,1)\n",
    "labels_std = np.array(stats[\"labels_stats\"][\"std\"]).reshape(5,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_mask included in gt_mask? False\n",
      "gt_mask included in mean_mask? True\n",
      "mean_mask included in gt_mask? False\n",
      "gt_mask included in mean_mask? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# iterate and standardize\n",
    "variables = ['P95', 'MeanH', 'Dens', 'Gini', 'Cover']\n",
    "def add(arr, source, state, pid):\n",
    "    arr = arr.reshape(-1,)   \n",
    "    data[\"number\"].extend(arr.tolist())\n",
    "    for variable in variables:\n",
    "        data[\"variables\"].extend([variable for _ in range(int(arr.shape[0]//5))])\n",
    "    data[\"sources\"].extend([source for _ in range(arr.shape[0])])\n",
    "    data[\"states\"].extend([state for _ in range(arr.shape[0])])\n",
    "    data[\"project_id\"].extend([pid for _ in range(arr.shape[0])])\n",
    "MAX_PROJECTS = 2\n",
    "counter = 0\n",
    "data = {\n",
    "    \"number\": [],\n",
    "    \"variables\": [],\n",
    "    \"sources\": [],\n",
    "    \"states\": [],\n",
    "    \"project_id\": [],\n",
    "}\n",
    "for mean_file in tqdm(Path(cfg[\"prediction_dir\"]).glob('*_mean.tif')):\n",
    "# for mean_file in Path(\"/scratch/ewalt/pdm/rs-uncertainty/results/2023-04-05_15-46-48\").glob('*_mean.tif'):\n",
    "    counter += 1\n",
    "    # load data\n",
    "    project = mean_file.stem.split('_')[0]\n",
    "    if project not in projects: continue\n",
    "    with rasterio.open(mean_file) as fh:\n",
    "        mean = fh.read(fh.indexes)\n",
    "    with rasterio.open(pjoin(cfg['prediction_dir'], f\"{project}_variance.tif\")) as fh:\n",
    "    # with rasterio.open(pjoin(\"/scratch/ewalt/pdm/rs-uncertainty/results/2023-04-05_15-46-48\", f\"{project}_variance.tif\")) as fh:\n",
    "        variance = fh.read(fh.indexes)\n",
    "    with rasterio.open(pjoin(cfg['gt_dir'], f\"{project}.tif\")) as fh:\n",
    "        gt = fh.read(fh.indexes)\n",
    "        gt_mask = fh.read_masks(1).astype(np.bool_)\n",
    "        gt[2] /= 100\n",
    "        gt[4] /= 100\n",
    "    # print(gt.shape, gt_mask.shape, np.isnan(mean).shape)\n",
    "    # standardize\n",
    "    variance_after = variance/(labels_std)**2\n",
    "    mean_after = (mean-labels_mean)/labels_std\n",
    "    gt_after = (gt-labels_mean)/labels_std \n",
    "    # mask\n",
    "    mean_mask = ~np.isnan(mean).all(0)\n",
    "    print(\"mean_mask included in gt_mask?\", (gt_mask[mean_mask==False]==False).all())\n",
    "    print(\"gt_mask included in mean_mask?\", (mean_mask[gt_mask==False]==False).all())\n",
    "    mask = np.logical_and(~np.isnan(mean).all(0), gt_mask)\n",
    "    # print(mask.shape)\n",
    "    mean = mean[:,mask]\n",
    "    variance = variance[:,mask]\n",
    "    gt = gt[:,mask]\n",
    "    mean_after = mean_after[:,mask]\n",
    "    variance_after = variance_after[:,mask]\n",
    "    gt_after = gt_after[:,mask]\n",
    "    # add flatten\n",
    "    add(mean, \"before\", \"mean\", project)\n",
    "    add(mean_after, \"after\", \"mean\", project)\n",
    "    add(variance, \"before\", \"variance\", project)\n",
    "    add(variance_after, \"after\", \"variance\", project)\n",
    "    add(gt, \"before\", \"gt\", project)\n",
    "    add(gt_after, \"after\", \"gt\", project)\n",
    "    if counter == MAX_PROJECTS: break\n",
    "data = pd.DataFrame(data)\n",
    "data.dropna(inplace=True)\n",
    "data.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>variables</th>\n",
       "      <th>sources</th>\n",
       "      <th>states</th>\n",
       "      <th>project_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.502655</td>\n",
       "      <td>P95</td>\n",
       "      <td>before</td>\n",
       "      <td>mean</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.068137</td>\n",
       "      <td>P95</td>\n",
       "      <td>before</td>\n",
       "      <td>mean</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.986108</td>\n",
       "      <td>P95</td>\n",
       "      <td>before</td>\n",
       "      <td>mean</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.772894</td>\n",
       "      <td>P95</td>\n",
       "      <td>before</td>\n",
       "      <td>mean</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.092015</td>\n",
       "      <td>P95</td>\n",
       "      <td>before</td>\n",
       "      <td>mean</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5736325</th>\n",
       "      <td>-2.572854</td>\n",
       "      <td>Cover</td>\n",
       "      <td>after</td>\n",
       "      <td>gt</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5736326</th>\n",
       "      <td>-2.572482</td>\n",
       "      <td>Cover</td>\n",
       "      <td>after</td>\n",
       "      <td>gt</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5736327</th>\n",
       "      <td>-2.570996</td>\n",
       "      <td>Cover</td>\n",
       "      <td>after</td>\n",
       "      <td>gt</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5736328</th>\n",
       "      <td>-2.572854</td>\n",
       "      <td>Cover</td>\n",
       "      <td>after</td>\n",
       "      <td>gt</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5736329</th>\n",
       "      <td>-2.573597</td>\n",
       "      <td>Cover</td>\n",
       "      <td>after</td>\n",
       "      <td>gt</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5736330 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            number variables sources states project_id\n",
       "0         8.502655       P95  before   mean        354\n",
       "1        10.068137       P95  before   mean        354\n",
       "2         9.986108       P95  before   mean        354\n",
       "3         9.772894       P95  before   mean        354\n",
       "4        10.092015       P95  before   mean        354\n",
       "...            ...       ...     ...    ...        ...\n",
       "5736325  -2.572854     Cover   after     gt        439\n",
       "5736326  -2.572482     Cover   after     gt        439\n",
       "5736327  -2.570996     Cover   after     gt        439\n",
       "5736328  -2.572854     Cover   after     gt        439\n",
       "5736329  -2.573597     Cover   after     gt        439\n",
       "\n",
       "[5736330 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\"mean\", \"gt\"]\n",
    "fig, axs = plt.subplots(nrows=len(data.variables.unique()), ncols=len(states), figsize=(20,20))\n",
    "for i, variable in enumerate(data.variables.unique()):\n",
    "    for j, state in enumerate(states):\n",
    "        if state==\"variance\": continue\n",
    "        sub = data.copy()\n",
    "        sub = sub[sub.variables==variable]\n",
    "        sub = sub[sub.states==state]\n",
    "        sns.histplot(data=sub, x=\"number\", hue=\"sources\", kde=True, ax=axs[i,j])\n",
    "        axs[i,j].set_title(f\"{state} {variable}\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"notebooks/standardization_mean_gt.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\"mean\", \"gt\"]\n",
    "variables = [\"MeanH\", \"P95\", \"Gini\"]\n",
    "fig, axs = plt.subplots(nrows=len(variables), ncols=len(states), figsize=(10,6))\n",
    "for i, variable in enumerate(variables):\n",
    "    for j, state in enumerate(states):\n",
    "        if state==\"variance\": continue\n",
    "        sub = data.copy()\n",
    "        sub = sub[sub.variables==variable]\n",
    "        sub = sub[sub.states==state]\n",
    "        sns.histplot(data=sub, x=\"number\", hue=\"sources\", kde=True, ax=axs[i,j])\n",
    "        axs[i,j].set_title(f\"{state} {variable}\")\n",
    "fig.suptitle(\"Projects: {}\".format(\" \".join(list(data.project_id.unique()))))\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"notebooks/standardization_ok.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\"mean\", \"gt\"]\n",
    "variables = [\"Cover\", \"Dens\"]\n",
    "fig, axs = plt.subplots(nrows=len(variables), ncols=len(states), figsize=(10,4))\n",
    "for i, variable in enumerate(variables):\n",
    "    for j, state in enumerate(states):\n",
    "        if state==\"variance\": continue\n",
    "        sub = data.copy()\n",
    "        sub = sub[sub.variables==variable]\n",
    "        sub = sub[sub.states==state]\n",
    "        sns.histplot(data=sub, x=\"number\", hue=\"sources\", kde=True, ax=axs[i,j])\n",
    "        axs[i,j].set_title(f\"{state} {variable}\")\n",
    "fig.suptitle(\"Projects: {}\".format(\" \".join(list(data.project_id.unique()))))\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"notebooks/standardization_issues.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to understand the issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are the predictions activated?\n",
    "with open(\"config/predict_testset/baseline.yaml\", \"r\") as f:\n",
    "    pcfg = yaml.safe_load(f)\n",
    "for i in range(len(pcfg[\"checkpoint_dirs\"])):\n",
    "    with pjoin(pcfg[\"checkpoint_dirs\"][i], \"config.yaml\").open(\"r\") as f:\n",
    "        tmp = yaml.safe_load(f)\n",
    "        print(\n",
    "            pcfg[\"checkpoint_dirs\"][i].split(\"/\")[-1],\n",
    "            \"activate_mean:\",\n",
    "            tmp[\"training\"][\"activate_mean\"]\n",
    "        )\n",
    "# yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all gt before\n",
    "variables = ['P95', 'MeanH', 'Dens', 'Gini', 'Cover']\n",
    "f, axs = plt.subplots(nrows=len(variables), ncols=1, figsize=(8,10))\n",
    "for i, var in enumerate(variables):\n",
    "    tmp = data.query(f\"states == 'gt' & variables == '{var}' & sources == 'before'\")\n",
    "    sns.histplot(data=tmp, x=\"number\", ax=axs[i])\n",
    "    axs[i].set_title(f\"{var} (min={tmp.number.min():.3f}, max={tmp.number.max():.3f})\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"notebooks/normalized100_gt_distros.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_constraints_violations(df, variable, constraints):\n",
    "    var = df.query(f\"variables == '{variable}' & states != 'variance'\")\n",
    "    var_before = var[var.sources==\"before\"]\n",
    "    var_after = var[var.sources==\"after\"]\n",
    "    print(variable, \"violation rate:\")\n",
    "    for constraint in constraints:\n",
    "        gt_before_rate = var_before[var_before.states==\"gt\"].query(constraint).shape[0]/var_before[var_before.states==\"gt\"].shape[0]\n",
    "        gt_after_rate = var_after[var_after.states==\"gt\"].query(constraint).shape[0]/var_after[var_after.states==\"gt\"].shape[0]\n",
    "        mean_before_rate = var_before[var_before.states==\"mean\"].query(constraint).shape[0]/var_before[var_before.states==\"mean\"].shape[0]\n",
    "        mean_after_rate = var_after[var_after.states==\"mean\"].query(constraint).shape[0]/var_after[var_after.states==\"mean\"].shape[0]\n",
    "        print(f\"\\t{constraint}:\")\n",
    "        print(f\"\\t\\tbefore -> (gt={gt_before_rate*100:.2f}%,mean={mean_before_rate*100:.2f}%)\")\n",
    "        print(f\"\\t\\tafter  -> (gt={gt_after_rate*100:.2f}%,mean={mean_after_rate*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are the constraints verified\n",
    "variables = ['P95', 'MeanH', 'Dens', 'Gini', 'Cover']\n",
    "for i, var in enumerate(variables):\n",
    "    show_constraints_violations(\n",
    "        data,\n",
    "        var,\n",
    "        [\"number < 0\"] if i<2 else [\"number < 0\", \"number > 1\"]\n",
    "    )\n",
    "# For prediction yes, for gt P95, MeanH, Gini yes Dens, Cover no\n",
    "# which makes no sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Could it be that for some reason the Cover and Dens GT must be normalized ?\n",
    "# Compare mean_before with gt_after\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "for var in [\"Dens\", \"Cover\"]:\n",
    "    tmp = data[data.variables==var]\n",
    "    tmp_mean_before = data.query(\"states == 'mean' & sources == 'before'\")\n",
    "    tmp_gt_after = data.query(\"states == 'gt' & sources == 'after'\")\n",
    "    tmp_mean_before[\"set\"] = \"mean_before\"\n",
    "    tmp_gt_after[\"set\"] = \"gt_after\"\n",
    "    tmp = pd.concat([tmp_mean_before, tmp_gt_after])\n",
    "    sns.histplot(data=tmp, x=\"number\", hue=\"set\", kde=True)\n",
    "    plt.title(var)\n",
    "    plt.show()\n",
    "# They do seem pretty close... BUT there mean_before respects (0,1) constraint\n",
    "# while gt_after does not (<0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1664*480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt.shape, gt_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt[:,gt_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(mean).all(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(mean).all(axis=0, keepdims=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query(\"states == 'gt' & variables == 'P95'\").number.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gt==-9.99999000e+05).sum()/gt.reshape(-1,).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gt<0).sum()/gt.reshape(-1,).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(pjoin(cfg['gt_dir'], f\"{project}.tif\")) as fh:\n",
    "    gt = fh.read(fh.indexes)\n",
    "    gt_mask = fh.read_masks(1).astype(np.bool_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "([gt==-9.99999000e+05]==gt_mask).sum()/gt_mask.reshape(-1,).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt.shape, gt_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(((gt[0]==-9.99999000e+05)==gt_mask))/(gt_mask.shape[0]*gt_mask.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probably_ok = (gt[0]!=-9.99999000e+05)\n",
    "definitely_ok = gt_mask\n",
    "plt.imshow(probably_ok)\n",
    "plt.show()\n",
    "plt.imshow(definitely_ok)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logical_and(probably_ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "definitely_ok[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.isnan(mean)==([gt==-9.99999000e+05]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bfs-3.7)",
   "language": "python",
   "name": "bfs-3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

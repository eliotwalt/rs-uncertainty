{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c01a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.chdir(\"/scratch/ewalt/pdm/rs-uncertainty\")\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "from src.metrics import StratifiedRCU\n",
    "from src.viz import *\n",
    "from pathlib import Path\n",
    "import rasterio\n",
    "import fiona\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import trange\n",
    "import random\n",
    "import yaml\n",
    "import fiona\n",
    "import rasterio.warp\n",
    "import rasterio.features\n",
    "sns.set()\n",
    "sns.set_style(\"whitegrid\")\n",
    "random.seed(123)\n",
    "\n",
    "RESDIR = \"results/cloud_exp/2023-06-20_16-14-11\" #\"results/cloud_exp/2023-05-26_15-55-46\"\n",
    "S2DIR = \"gee_data/reprojected/\"\n",
    "S2REPRDIR = \"gee_data/reprojected_dirs\"\n",
    "GTDIR = \"assets/data/preprocessed\"\n",
    "SANITYRESDIR = \"results/cloud_exp/2023-05-31_11-23-56_sanity_check\" # results\n",
    "SANITYS2DIR = \"assets/data/sentinel_data/s2_reprojected\" # s2 reprojected\n",
    "SANITYS2REPRDIR = \"gee_data/sanity_check/\" # restructured s2 reprojected\n",
    "SPLITMASKDIR = \"assets/data/split_masks/\" # split masks\n",
    "SHAPEFILES = ['assets/data/NHM_projectDekning_AOI_edit2015_V2.shp', 'assets/data/ALS_projects_Dz_all_norway.shp']\n",
    "STATSFILE = \"data/2023-04-05_18-58-33_baseline/stats.yaml\"\n",
    "EMPIRICAL_CP_THRESHOLD = 7.9\n",
    "\n",
    "with open(STATSFILE, \"r\") as f:\n",
    "    stats = yaml.safe_load(f)\n",
    "TRAINMEANS = stats[\"labels_stats\"][\"mean\"]\n",
    "TRAINSTDS = stats[\"labels_stats\"][\"std\"]\n",
    "for i in [2,4]:\n",
    "    TRAINMEANS[i] /= 100\n",
    "    TRAINSTDS[i] /= 100\n",
    "    \n",
    "VARIABLES = ['P95', 'MeanH', 'Dens', 'Gini', 'Cover']\n",
    "\n",
    "# Experiment result directories\n",
    "result_dirs = [p.path for p in os.scandir(RESDIR) if os.path.exists(os.path.join(p.path,\"rcu.json\"))]\n",
    "outliers = [os.path.join(RESDIR, f\"1023_{d}\") for d in [\n",
    "    \"20180503T104019\", # index: 3, avgcp: 42, all white\n",
    "    \"20180620T105031\", # index: 6, avgcp: 0., all white\n",
    "]]\n",
    "result_dirs = [r for r in result_dirs if not any(r.__contains__(o) for o in outliers)]\n",
    "len(result_dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b781ad6",
   "metadata": {},
   "source": [
    "## Random 4 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd820aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4,nrows=1,figsize=(12,6))\n",
    "axs = axs.flatten()\n",
    "def showOnAxis(d, ax):\n",
    "    p = getPaths(d, s2repr_dirs=S2REPRDIR, returns=[\"img\"])\n",
    "    rgb = loadRaster(p, transpose_order=(1,2,0), clip_range=(100,2000), bands=[4,3,2])\n",
    "    ax.imshow(rgb)\n",
    "    ax.set_axis_off()\n",
    "for d in os.scandir(RESDIR):\n",
    "    dd = d.path\n",
    "    if \"20180630T\" in dd: showOnAxis(dd, axs[0])\n",
    "    elif \"20180627\" in dd: showOnAxis(dd, axs[1])\n",
    "    elif \"20180707\" in dd: showOnAxis(dd, axs[2])\n",
    "    elif \"20180824\" in dd: showOnAxis(dd, axs[3])\n",
    "plt.tight_layout()\n",
    "savefigure(fig, \"images/albecker/random_4_cond\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adeb3f8",
   "metadata": {},
   "source": [
    "## Empirical Cp threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fb16c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeEmpiricalCpDistribution(config):\n",
    "    all_cps = np.arange(0, 101)\n",
    "    cps_histogram = np.zeros((100,))\n",
    "    selected_cps_histogram = np.zeros((100,))\n",
    "    cnt = 0\n",
    "    for i, gt_file_path in enumerate(Path(config[\"gt_dir\"]).glob(\"*.tif\")):\n",
    "        project_id = gt_file_path.stem\n",
    "        if (project_id in config[\"projects\"] and \n",
    "            os.path.exists(os.path.join(config[\"s2_reprojected_dir\"], project_id))):\n",
    "            cnt += 1\n",
    "            print(f\"Processing {project_id} [{cnt}/{len(config['projects'])}]\")\n",
    "            # get gt_file and valid_mask\n",
    "            gt_file = rasterio.open(gt_file_path)\n",
    "            valid_mask = gt_file.read_masks(1)\n",
    "            # read split mask\n",
    "            with rasterio.open(os.path.join(config[\"split_mask_dir\"], f\"{project_id}.tif\")) as f:\n",
    "                split_mask = f.read(1).astype(\"float16\")\n",
    "            assert valid_mask.shape==split_mask.shape\n",
    "            # rasterized polygon and gt date\n",
    "            project_shape_collections = [fiona.open(p) for p in config['project_shapefiles']]\n",
    "            # create the shape (\"polygon\") associated to the project \n",
    "            polygon, crs, gt_date = None, None, None\n",
    "            for collection in project_shape_collections:\n",
    "                try:\n",
    "                    polygon = [s['geometry'] for s in collection if s['properties']['kv_id'] == int(project_id)][0]\n",
    "                    crs = collection.crs\n",
    "                    gt_date = [s[\"properties\"][\"PUB_DATO\"] for s in collection if s['properties']['kv_id'] == int(project_id)][0]\n",
    "                    gt_date = parse_gt_date(gt_date)\n",
    "                    break\n",
    "                except IndexError: pass \n",
    "            if polygon is None: print(\"No polygon found\")\n",
    "            polygon = rasterio.warp.transform_geom(src_crs=crs, dst_crs=gt_file.crs, geom=polygon)\n",
    "            rasterized_polygon = rasterio.features.rasterize(\n",
    "                [(polygon, 1)],\n",
    "                out_shape=gt_file.shape,\n",
    "                transform=gt_file.transform,\n",
    "                fill=0,\n",
    "                dtype='uint8'\n",
    "            )\n",
    "            # read s2 images\n",
    "            parse_date = lambda x: datetime.strptime(x, '%Y%m%d')\n",
    "            s2_images = []\n",
    "            for img_path in Path(os.path.join(config[\"s2_reprojected_dir\"], project_id)).glob(\"*.tif\"):\n",
    "                with rasterio.open(img_path) as fh:\n",
    "                    s2_images.append((fh.read(fh.indexes), parse_date(img_path.stem.split('_')[3].split('T')[0])))\n",
    "            # Get valid centers\n",
    "            shape = gt_file.shape\n",
    "            patch_half = config[\"patch_size\"]//2\n",
    "            for i in trange(patch_half, gt_file.shape[0] - patch_half):\n",
    "                for j in range(patch_half, gt_file.shape[1] - patch_half):\n",
    "                    i_slice = slice(i - patch_half, i + patch_half + 1)\n",
    "                    j_slice = slice(j - patch_half, j + patch_half + 1)\n",
    "                    is_train_split = (split_mask[i_slice, j_slice] == 0).all()\n",
    "                    is_in_polygon = (rasterized_polygon[i_slice, j_slice] == 1).all()\n",
    "                    # Ignore pixels that span out of train split and don't lie completly in their polygon\n",
    "                    if is_train_split and is_in_polygon and valid_mask[i,j]:\n",
    "                        for s2_image, s2_date in s2_images:\n",
    "                            cps = s2_image[-1, i_slice, j_slice].reshape((-1))\n",
    "                            cp_histcount, _ = np.histogram(cps, all_cps)\n",
    "                            cps_histogram += cp_histcount\n",
    "                            if (s2_image[-1, i_slice, j_slice] > config['cloud_prob_threshold']).sum() \\\n",
    "                                / config['patch_size']**2 > config['cloudy_pixels_threshold']:\n",
    "                                continue\n",
    "                            else:\n",
    "                                selected_cps_histogram += cp_histcount\n",
    "            # close gt file\n",
    "            gt_file.close()\n",
    "    cp_df = pd.DataFrame({\n",
    "        \"cp\": np.arange(0, 100),\n",
    "        \"cp_count\": cps_histogram,\n",
    "        \"selected\": selected_cps_histogram,\n",
    "        \"rejected\": cps_histogram-selected_cps_histogram,\n",
    "    })\n",
    "    cp_df = cp_df.assign(\n",
    "        selection_probability=cp_df.selected/cp_df.cp_count,\n",
    "        rejection_probability=cp_df.rejected/cp_df.cp_count\n",
    "    )\n",
    "    return cp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780b59fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config/create_dataset/baseline.yaml\", \"r\") as f: \n",
    "    baseline_config = yaml.safe_load(f)\n",
    "if os.path.exists(os.path.join(\"computed_resources\", \"train_set_pixels_cps.json\")):\n",
    "    cp_df = pd.read_json(os.path.join(\"computed_resources\", \"train_set_pixels_cps.json\"))\n",
    "else:\n",
    "    cp_df = computeEmpiricalCpDistribution(baseline_config)\n",
    "    cp_df.to_json(os.path.join(\"computed_resources\", \"train_set_pixels_cps.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154e7991",
   "metadata": {},
   "outputs": [],
   "source": [
    "showEmpiricalSelectionRejectionProbs(\n",
    "    cp_df,\n",
    "    EMPIRICAL_CP_THRESHOLD,\n",
    "    interpolate=True,\n",
    "    figsize=(12,5),\n",
    "    save_name=\"images/albecker/empirical_selection_rejection_proba\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eaffc9",
   "metadata": {},
   "source": [
    "## Validity masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523890a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"1023\"\n",
    "d = os.path.join(RESDIR, '1023_20180526T105029')\n",
    "gt_path, img_path = getPaths(d, s2repr_dirs=S2REPRDIR, gt_dir=GTDIR, returns=[\"gt\", \"img\"])\n",
    "with rasterio.open(gt_path) as f:\n",
    "    gts = []\n",
    "    gt_mask = f.read_masks(1)//255\n",
    "    for i in range(1,f.count+1):\n",
    "        gt = f.read(i)\n",
    "        gt[gt_mask==0] = np.nan\n",
    "        gt[gt>0] = 100\n",
    "        gts.append(gt)\n",
    "    gt = np.nanmean(np.stack(gts, axis=0), axis=0)\n",
    "    project_shape_collections = [fiona.open(p) for p in baseline_config['project_shapefiles']]\n",
    "    # create the shape (\"polygon\") associated to the project \n",
    "    polygon, crs, gt_date = None, None, None\n",
    "    for collection in project_shape_collections:\n",
    "        try:\n",
    "            polygon = [s['geometry'] for s in collection if s['properties']['kv_id'] == int(project_id)][0]\n",
    "            crs = collection.crs\n",
    "            gt_date = [s[\"properties\"][\"PUB_DATO\"] for s in collection if s['properties']['kv_id'] == int(project_id)][0]\n",
    "            gt_date = parse_gt_date(gt_date)\n",
    "            break\n",
    "        except IndexError: pass \n",
    "    if polygon is None: print(\"No polygon found\")\n",
    "    polygon = rasterio.warp.transform_geom(src_crs=crs, dst_crs=f.crs, geom=polygon)\n",
    "    rasterized_polygon = rasterio.features.rasterize(\n",
    "        [(polygon, 1)],\n",
    "        out_shape=f.shape,\n",
    "        transform=f.transform,\n",
    "        fill=0,\n",
    "        dtype='float32'\n",
    "    )\n",
    "# selected=1, rejected=-1\n",
    "rasterized_polygon[rasterized_polygon==0] = -1\n",
    "rasterized_polygon[rasterized_polygon==1] = 1\n",
    "gt[~np.isnan(gt)] = 1\n",
    "gt[np.isnan(gt)] = -1\n",
    "rgb = loadRaster(img_path, bands=[4,3,2], clip_range=(100, 2000), transpose_order=(1,2,0))\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(12, 3.5))\n",
    "axs[0].imshow(rgb)\n",
    "axs[1].imshow(rgb)\n",
    "axs[2].imshow(rgb)\n",
    "sns.heatmap(rasterized_polygon, ax=axs[1], cbar=False, cmap=\"magma\", alpha=0.6)\n",
    "sns.heatmap(gt, ax=axs[2], cbar=False, cmap=\"bwr_r\", alpha=0.6)\n",
    "for ax in axs: ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/albecker/1023_validity_mask_and_polygon.png\", dpi=300)\n",
    "# plt.savefig(\"images/albecker/1023_validity_mask_and_polygon.pdf\", dpi=72)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86522b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid mask for other project for report\n",
    "project_id = \"805\"\n",
    "gt_path = \"assets/data/preprocessed/805.tif\"\n",
    "img_path = \"assets/data/sentinel_data/s2_reprojected/805/805_S2B_MSIL2A_20170720T105029_N9999_R051_T32VNN_20201207T094930.tif\"\n",
    "with rasterio.open(gt_path) as f:\n",
    "    gts = []\n",
    "    gt_mask = f.read_masks(1)//255\n",
    "    for i in range(1,f.count+1):\n",
    "        gt = f.read(i)\n",
    "        gt[gt_mask==0] = np.nan\n",
    "        gt[gt>0] = 100\n",
    "        gts.append(gt)\n",
    "    gt = np.nanmean(np.stack(gts, axis=0), axis=0)\n",
    "    project_shape_collections = [fiona.open(p) for p in baseline_config['project_shapefiles']]\n",
    "    # create the shape (\"polygon\") associated to the project \n",
    "    polygon, crs, gt_date = None, None, None\n",
    "    for collection in project_shape_collections:\n",
    "        try:\n",
    "            polygon = [s['geometry'] for s in collection if s['properties']['kv_id'] == int(project_id)][0]\n",
    "            crs = collection.crs\n",
    "            gt_date = [s[\"properties\"][\"PUB_DATO\"] for s in collection if s['properties']['kv_id'] == int(project_id)][0]\n",
    "            gt_date = parse_gt_date(gt_date)\n",
    "            break\n",
    "        except IndexError: pass \n",
    "    if polygon is None: print(\"No polygon found\")\n",
    "    polygon = rasterio.warp.transform_geom(src_crs=crs, dst_crs=f.crs, geom=polygon)\n",
    "    rasterized_polygon = rasterio.features.rasterize(\n",
    "        [(polygon, 1)],\n",
    "        out_shape=f.shape,\n",
    "        transform=f.transform,\n",
    "        fill=0,\n",
    "        dtype='float32'\n",
    "    )\n",
    "# selected=1, rejected=-1\n",
    "rasterized_polygon[rasterized_polygon==0] = -1\n",
    "rasterized_polygon[rasterized_polygon==1] = 1\n",
    "gt[~np.isnan(gt)] = 1\n",
    "gt[np.isnan(gt)] = -1\n",
    "rgb = loadRaster(img_path, bands=[4,3,2], clip_range=(100, 2000), transpose_order=(1,2,0))\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(12, 8))\n",
    "axs[0].imshow(rgb)\n",
    "axs[1].imshow(rgb)\n",
    "axs[2].imshow(rgb)\n",
    "sns.heatmap(rasterized_polygon, ax=axs[1], cbar=False, cmap=\"magma\", alpha=0.6)\n",
    "sns.heatmap(gt, ax=axs[2], cbar=False, cmap=\"bwr_r\", alpha=0.6)\n",
    "for ax in axs: ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/albecker/805_validity_mask_and_polygon.png\", dpi=300)\n",
    "# plt.savefig(\"images/albecker/1023_validity_mask_and_polygon.pdf\", dpi=72)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdal-rio-3.7",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
